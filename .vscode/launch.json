{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: finetune",
            "type": "python",
            "request": "launch",
            "program": "finetune.py",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--base_model",
                "'decapoda-research/llama-7b-hf'",
                "--data_path",
                "'math_data.json' ",
                "--output_dir",
                "'./trained_models/llama-lora'",
                "--batch_size",
                "16",
                "--micro_batch_size",
                "4",
                "--num_epochs",
                "3",
                "--learning_rate",
                "3e-4",
                "--cutoff_len",
                "256",
                "--val_set_size",
                "120",
                "--adapter_name",
                "bottleneck",
                "--use_global_kv_adapter",
            ]
        }
    ]
}